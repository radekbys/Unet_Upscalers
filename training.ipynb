{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semester assignment\n",
    "* In this notebook I will create a convolutionary neural network\n",
    "* I plan it to be a 2x upscaler\n",
    "* I will use PyTorch library for model, training and interference\n",
    "* I will use OpenCV for image processing\n",
    "* I will use DIV2K dataset aviable at https://www.kaggle.com/datasets/joe1995/div2k-dataset/data?select=DIV2K_train_HR\n",
    "* I will use a Unet architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Importing needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import kagglehub\n",
    "import pathlib\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import torchmetrics\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Downloading dataset before moving it to project location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Download latest version of dataset\n",
    "# path = kagglehub.dataset_download(\"joe1995/div2k-dataset\")\n",
    "# print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Resizing images\n",
    "\n",
    "FOr supervised training two sets of images are needed, one in the base resolution tat will be upscaled and one in the target resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_path = pathlib.Path(\"./dataset/DIV2K_train_HR\")\n",
    "\n",
    "# for i in range(1, 801):\n",
    "#     image = cv2.imread(base_path / \"DIV2K_train_HR\" / f\"{i:04d}.png\")  # reading image\n",
    "#     large_image = cv2.resize(image, (1280, 720))\n",
    "#     cv2.imwrite(\n",
    "#         base_path / \"Large\" / f\"{i:04d}.png\", large_image\n",
    "#     )  # saving large image for y tensor in training\n",
    "\n",
    "#     small_image = cv2.resize(large_image, (640, 360))\n",
    "#     cv2.imwrite(base_path / \"Downscaled\" / f\"{i:04d}.png\", small_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_path = pathlib.Path(\"./dataset/DIV2K_valid_HR\")\n",
    "\n",
    "# for i in range(801, 901):\n",
    "#     image = cv2.imread(base_path / \"DIV2K_valid_HR\" / f\"{i:04d}.png\")  # reading image\n",
    "#     large_image = cv2.resize(image, (1280, 720))\n",
    "#     cv2.imwrite(\n",
    "#         base_path / \"Large\" / f\"{i:04d}.png\", large_image\n",
    "#     )  # saving large image for y tensor in training\n",
    "\n",
    "#     small_image = cv2.resize(large_image, (640, 360))\n",
    "#     cv2.imwrite(base_path / \"Downscaled\" / f\"{i:04d}.png\", small_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Creating training and testing datasets\n",
    "\n",
    "* to create this datasets I prepared a custom dataset class based on torch.utils.data.Dataset\n",
    "* it loads all the images ussed below to ram memory to significantly speed up the learning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DIV2KDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Define the paths for downscaled and large images\n",
    "        self.downscaled_dir = os.path.join(root_dir, 'Downscaled')\n",
    "        self.large_dir = os.path.join(root_dir, 'Large')\n",
    "        \n",
    "        # List all image files in the downscaled directory\n",
    "        self.image_filenames = sorted(os.listdir(self.downscaled_dir))\n",
    "        \n",
    "        # Preload all data into RAM\n",
    "        self.data = []\n",
    "        for filename in self.image_filenames:\n",
    "            # Load downscaled image\n",
    "            downscaled_path = os.path.join(self.downscaled_dir, filename)\n",
    "            large_path = os.path.join(self.large_dir, filename)\n",
    "            \n",
    "            X = cv2.imread(downscaled_path)\n",
    "            X = cv2.cvtColor(X, cv2.COLOR_BGR2RGB)\n",
    "            X = X.astype(np.float32) / 255.0\n",
    "            \n",
    "            y = cv2.imread(large_path)\n",
    "            y = cv2.cvtColor(y, cv2.COLOR_BGR2RGB)\n",
    "            y = y.astype(np.float32) / 255.0\n",
    "            \n",
    "            if self.transform:\n",
    "                X = self.transform(X)\n",
    "                y = self.transform(y)\n",
    "            \n",
    "            self.data.append((X, y))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DIV2KDataset(root_dir='dataset/DIV2K_train_HR', transform=transforms.ToTensor())\n",
    "testing_dataset = DIV2KDataset(root_dir='dataset/DIV2K_valid_HR', transform=transforms.ToTensor())\n",
    "\n",
    "len(train_dataset), len(testing_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualization\n",
    "Here I am checking if the datasets have been created correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,3))\n",
    "plt.title(\"Example Images\", fontsize=16)\n",
    "plt.axis(\"off\")\n",
    "for i, (image, target) in enumerate(train_dataset):\n",
    "    if i >= 5:\n",
    "        break\n",
    "    plt.subplot(1, 5, i+1)\n",
    "    plt.title(f\"image: {i}\", fontsize=14)\n",
    "    plt.imshow(image.squeeze().permute(1,2,0).cpu())\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating dataloaders\n",
    "\n",
    "* dataloaders are needed to access images in batches to perform training.\n",
    "* training on whole dataset at once is not viable, becauase it would use way too mych vram\n",
    "* I use batch size of 1, beacouse of vram limitations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, 1, shuffle=True)\n",
    "test_dataloader = DataLoader(testing_dataset, 1, shuffle=False)\n",
    "len(train_dataloader), len(test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Creating a model\n",
    "\n",
    "* The below model is my implementation of U-net architecture\n",
    "* In first step I increase the image size to make it viable for downsampling during the descent into the U-net\n",
    "* Then I downsample the data the data two times, and increase the number of channels in the convolution layers\n",
    "* Downsampling is used to find patterns in the data\n",
    "* Next I upsample the data once while reducing the number of channels\n",
    "* The last part is a series of convolution layers that connect all the information into a single 3 channel image\n",
    "\n",
    "### Layers used:\n",
    "* I use Conv2d layers for convolution, I theke the parameters to more or less fit the size of image Iam convoluting at each layer\n",
    "* I use LeakyReLU layers to provide nonlinearity, to prevent occurence of dead neurons, and to prevent overfitting so I don't need to use dropout layers\n",
    "* I use UpsamplingNearest2d to increase the image dimensions when needed\n",
    "* I also use AvgPool2d to reduce image sizes when needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnetUpscaler(torch.nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.layers = torch.nn.Sequential(\n",
    "            # initial upsampling\n",
    "            torch.nn.UpsamplingNearest2d(scale_factor=2),\n",
    "            \n",
    "            torch.nn.Conv2d(3, 16, 5, 1, 4, 2),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Conv2d(16, 64, 5, 1, 4, 2),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Conv2d(64, 256, 5, 1, 4, 2),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Conv2d(256, 64, 5, 1, 4, 2),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Conv2d(64, 64, 3, 1, 1, 1),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Conv2d(64, 64, 3, 1, 1, 1),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Conv2d(64, 64, 3, 1, 1, 1),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Conv2d(64, 16, 3, 1, 1, 1),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Conv2d(16, 3, 3, 1, 1, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "\n",
    "\n",
    "model_01 = UnetUpscaler().to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = model_01(train_dataset[0][0].unsqueeze(0).to(\"cuda\"))\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example output image without training\n",
    "\n",
    "plt.figure(figsize=(16 ,9))\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(y.squeeze().permute(1,2,0).cpu().detach())\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Creating Optimizer and loss function, and loading model from a checkpoint\n",
    "\n",
    "* as optimizer I used the Adam algorithm. It is a standard popular optimizer, and in the past I achived better results with it than with basic SGD\n",
    "* as cost function I have experimented with L1Loss and smoothL1Loss. In theory L1Loss should give sharper images, though I haven't foung much diffrence in my results\n",
    "* I created checkpoints in the training sessions, so I dont have to perform all the training at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights = torch.load(\"upscaler_ver_08_e40.pt\", weights_only=True)\n",
    "# model_01 = UnetUpscaler()\n",
    "# model_01.load_state_dict(weights)\n",
    "# model_01.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optimizer = torch.optim.Adam(params = model_01.parameters(), lr=0.00001)\n",
    "cost_fn = torch.nn.SmoothL1Loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Training\n",
    "\n",
    "* Here I perform a standard training loop\n",
    "* I use my RTX 4070 for training, which is a cuda device\n",
    "* I perfor evaluation once every 80 batches\n",
    "* I collect each loss value of every batch and calculate the average in evaluation\n",
    "* To compare it with a testing sample i choose a random image from the testing dataset\n",
    "* I also use mean square error for evaluation, it can be used for evaluating regression models like this one\n",
    "* After the training is finishe I save the final model weights\n",
    "* 100cepochs of trainig takes around 6 hours\n",
    "* this particular model I stopped training after 70 peochs, because I saw overfitting, training losses were girng down, while test losses started climbing up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "metric = torchmetrics.MeanSquaredError().to(\"cuda\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    losses = []\n",
    "    for i, (X, y) in tqdm(enumerate(train_dataloader)):\n",
    "        model_01.train()\n",
    "        X = X.to(\"cuda\")\n",
    "        y = y.to(\"cuda\")\n",
    "        output = model_01(X)\n",
    "        loss = cost_fn(input=output, target=y)\n",
    "        losses.append(loss.item())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (i + 1) % 800 == 0:\n",
    "            model_01.eval()\n",
    "            with torch.inference_mode():\n",
    "\n",
    "                test_losses = []\n",
    "                mserrors = []\n",
    "                for j in range(100):\n",
    "                    # idx = random.random()\n",
    "                    # idx = int(idx * 100)\n",
    "                    idx = j\n",
    "                    X = testing_dataset[idx][0].unsqueeze(0).to(\"cuda\")\n",
    "                    y = testing_dataset[idx][1].unsqueeze(0).to(\"cuda\")\n",
    "                    test_output = model_01(X)\n",
    "                    test_loss = cost_fn(input=test_output, target=y)\n",
    "                    test_losses.append(test_loss.item())\n",
    "                    mse = metric(test_output, y)\n",
    "                    mserrors.append(mse)\n",
    "\n",
    "                train_loss = sum(losses) / len(losses)\n",
    "                test_loss = sum(test_losses) / len(test_losses)\n",
    "                mse = sum(mserrors) / len(mserrors)\n",
    "\n",
    "                print(\n",
    "                    f\"epoch: {epoch+1} || train_loss: {train_loss} || test_loss: {test_loss} || mean square error: {mse}\"\n",
    "                )\n",
    "                losses.clear()\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        torch.save(model_01.state_dict(), f\"upscaler_ver_09_e{epoch+1}.pt\")\n",
    "\n",
    "torch.save(model_01.state_dict(), f\"upscaler_ver_09_e{100}.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
